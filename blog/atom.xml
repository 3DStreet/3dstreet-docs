<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://3dstreet.org/blog</id>
    <title>3DStreet Blog</title>
    <updated>2023-12-29T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://3dstreet.org/blog"/>
    <subtitle>3DStreet Blog</subtitle>
    <icon>https://3dstreet.org/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[Impact on WebXR Application Design from New Mixed Reality Headsets]]></title>
        <id>https://3dstreet.org/blog/2023/12/29/new-mixed-reality-devices-impact-on-webxr</id>
        <link href="https://3dstreet.org/blog/2023/12/29/new-mixed-reality-devices-impact-on-webxr"/>
        <updated>2023-12-29T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[What changes should WebXR developers consider to their application given new devices coming to market?]]></summary>
        <content type="html"><![CDATA[<p>A few weeks ago I attended a "developer day" at a local electronics company down the road featuring their new mixed reality VR headset. I spent the entire day testing many different WebXR applications with a heavy focus on evaluating which user interaction elements will be relevant for developers.</p>
<p>Below are some notes intended for other 3DStreet code contributors to reference as we work on supporting new WebXR compatible devices.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="gaze-works-very-well-as-a-primary-user-input-mechanism">Gaze works very well as a primary user input mechanism<a href="https://3dstreet.org/blog/2023/12/29/new-mixed-reality-devices-impact-on-webxr#gaze-works-very-well-as-a-primary-user-input-mechanism" class="hash-link" aria-label="Direct link to Gaze works very well as a primary user input mechanism" title="Direct link to Gaze works very well as a primary user input mechanism">​</a></h2>
<p>Gaze interaction <em>"just works"</em> for native applications in this headset, however it's a privacy nightmare as gaze movement can be use to fingerprint (identify) individuals for tracking purposes, so that information isn't even given to native application.</p>
<p>To enable gaze user interface while not exposing gaze to the application, apps need to provide "hot spots" or hints as to areas that can be hovered. <a href="https://developer.apple.com/videos/play/wwdc2023/10279/" target="_blank" rel="noopener noreferrer">There is a great video guide on how to adapt 2D DOM CSS website for gaze highlight interaction</a>, but there's no clear equivalent to this CSS hinting that can be done in the WebXR "3D DOM" or 3D space. The need has been recognized however, <a href="https://github.com/immersive-web/proposals/issues/86" target="_blank" rel="noopener noreferrer">there is a new ticket opened in the WebXR <code>immersive-web</code> GitHub repository that I recently added to.</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="hand-tracking-is-the-most-accessible-input-not-controllers">Hand tracking is the most accessible input, not controllers<a href="https://3dstreet.org/blog/2023/12/29/new-mixed-reality-devices-impact-on-webxr#hand-tracking-is-the-most-accessible-input-not-controllers" class="hash-link" aria-label="Direct link to Hand tracking is the most accessible input, not controllers" title="Direct link to Hand tracking is the most accessible input, not controllers">​</a></h2>
<p>Imagine a world where WebXR experiences are 100% hands-free, where a simple ray from the wrist and a pitch of the hand can activate functions. This is not just a possibility but now a necessity -- going forward, all WebXR experiences must be accessible via hands first.</p>
<p>We should now regard hand tracking as the "lowest common denominator" of user input for headset experiences. Controllers will still offer higher precision, off-camera movement tracking, more button trigger inputs, etc. but they are no longer the most accessible "default" option.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="launching-webxr-applications">Launching WebXR applications<a href="https://3dstreet.org/blog/2023/12/29/new-mixed-reality-devices-impact-on-webxr#launching-webxr-applications" class="hash-link" aria-label="Direct link to Launching WebXR applications" title="Direct link to Launching WebXR applications">​</a></h2>
<p>Getting WebXR working on this device is cumbersome. WebXR must be activated by searching through multiple Safari flags (System Settings &gt; Apps &gt; Safari &gt; Blah blah blah). Then, on the web page itself a user must accept 2 separate approval popups when entering WebXR mode -- one for enabling immersive mode, the other for enabling hand tracking.</p>
<p>It may be possible to "pull" some advanced users into using WebXR on these devices with instruction on feature flag setting, but it will be impossible to use WebXR on this platform to "push" more people to your WebXR experience in its present form.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="space-immersion-and-passthrough-with-webxr">Space, Immersion and Passthrough with WebXR<a href="https://3dstreet.org/blog/2023/12/29/new-mixed-reality-devices-impact-on-webxr#space-immersion-and-passthrough-with-webxr" class="hash-link" aria-label="Direct link to Space, Immersion and Passthrough with WebXR" title="Direct link to Space, Immersion and Passthrough with WebXR">​</a></h2>
<p>In WebXR mode on the device, a scene is rendered in <em>Full Space</em> meaning no other application windows are present, unlike native apps that can choose to run in <em>Shared Space</em> amongst other applications. An additional limitation is that the device does not currently support WebXR with <em>Passthrough</em> mode, therefore you cannot run WebAR apps that make use of external cameras.</p>
<p><em>Therefore only your WebXR scene will appear in <em>Full Space</em> immersion mode with no <em>Passthrough</em>.</em> This may be desirable for traditional VR applications but not as useful for next generation mixed reality applications.</p>
<p>An additional limitation is that WebXR Immersive mode is limited to a 1.5m radius from the user-specified origin, usually where the user was located when entering XR mode. Beyond this radius the immersive scene <em>Full Space</em> begins fading into <em>Passthrough</em> without the scene persisting. If a user continues moving away from the origin the will see a round Safari icon at the origin point, presumably indicating that the user has an open WebXR Safari session with an origin at that point.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="diorama-vs-full-room-scale">Diorama vs. Full Room Scale<a href="https://3dstreet.org/blog/2023/12/29/new-mixed-reality-devices-impact-on-webxr#diorama-vs-full-room-scale" class="hash-link" aria-label="Direct link to Diorama vs. Full Room Scale" title="Direct link to Diorama vs. Full Room Scale">​</a></h2>
<p>The <a href="https://developer.apple.com/documentation/visionos/" target="_blank" rel="noopener noreferrer">visionOS developer documentation</a> is excellent and signals clear directions for the market.</p>
<p>The Diorama appears to be major application interface concept, <a href="https://developer.apple.com/documentation/visionos/diorama" target="_blank" rel="noopener noreferrer">featured as a sample application</a> and a prime example of output from the new Reality Composer Pro authoring tool.</p>
<p>This is a useful concept to adopt with 3DStreet. With 3DStreet there are cases for both Diorama and Full Scale modes: some users may wish to view a scene in Full Scale life-size to get an accurate viewpoint of dimension, while other users may wish to shrink a scene down to a Diorama view to easily manipulate a large scene from a smaller workspace.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="combining-webxr-with-native-applications">Combining WebXR with native applications<a href="https://3dstreet.org/blog/2023/12/29/new-mixed-reality-devices-impact-on-webxr#combining-webxr-with-native-applications" class="hash-link" aria-label="Direct link to Combining WebXR with native applications" title="Direct link to Combining WebXR with native applications">​</a></h2>
<ul>
<li>Native applications can ask for rights such as <em>Passthrough</em> or <em>Shared Space</em> that are not currently accessible via Safari WebXR. It is definitely worth exploring the use of an embedded webkit-based webview in a visionOS application which may expand the ability for WebXR application to offer augmented reality experiences with a native-like experience.</li>
<li>Reality Composer Pro looks like a powerful tool for non-developers. It is worth exploring a pipeline of 3DStreet &gt; Reality Composer Pro &gt; App Publishing. Therefore it is likely worth exploring tools to convert glTF exporting to USDZ format, or directly exporting the three.js / A-Frame scene into USDZ format.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary">Summary<a href="https://3dstreet.org/blog/2023/12/29/new-mixed-reality-devices-impact-on-webxr#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary">​</a></h2>
<ul>
<li>WebXR appears to be purposefully limited on this device with a degraded user experience. Consider webview or another mechanism to adapt WebXR application into a native app.</li>
<li>Hand tracking is now a minimum requirement for WebXR apps, controllers are optional.</li>
<li>Gaze interface is very effective but needs standardization work to enable in WebXR mode.</li>
</ul>]]></content>
        <author>
            <name>Kieran Farr</name>
            <uri>https://github.com/kfarr</uri>
        </author>
        <category label="webxr" term="webxr"/>
        <category label="headset" term="headset"/>
        <category label="mixed-reality" term="mixed-reality"/>
        <category label="ar" term="ar"/>
        <category label="vr" term="vr"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Creating novel 3D scenes by compositing Gaussian splats with A-Frame and three.js]]></title>
        <id>https://3dstreet.org/blog/2023/12/21/gaussian-splat-compositing-for-constructed-street-scenes</id>
        <link href="https://3dstreet.org/blog/2023/12/21/gaussian-splat-compositing-for-constructed-street-scenes"/>
        <updated>2023-12-21T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We share research and progress on improving the visual appearance of compositing new scenes from multiple splats using depth buffer and selective splat discarding.]]></summary>
        <content type="html"><![CDATA[<p>3DStreet's mission is to empower anyone to visualize safer streets. A common request to support this mission is to bring in local real-life elements from your actual streets by scanning them into 3D objects. Until now, the best technology for doing this (photogrammetry to textured 3D polygons) resulted in huge file sizes, difficult to edit output files, and gooey visuals like melting trees or cars that you may see on Google Maps in 3D mode.</p>
<p>Enter Gaussian Splatting -- earlier this year a groundbreaking photogrammetry and visualization technique called gaussian splatting was released as part of a <a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" target="_blank" rel="noopener noreferrer">research paper published at SIGGRAPH 2023</a>. I believe splatting to be <em><a href="https://www.youtube.com/watch?v=HVv_IQKlafQ" target="_blank" rel="noopener noreferrer">the best modern method</a></em> to allow everyday users like you and me to scan 3D objects with our phones and retain the fine detail of organic material especially <a href="https://www.youtube.com/watch?v=lowscL9YIjM" target="_blank" rel="noopener noreferrer">plants</a>, <a href="https://www.youtube.com/watch?v=hr7P8_z0PSk" target="_blank" rel="noopener noreferrer">trees</a>, flowers and other natural elements -- all things we'd like to see more of in our streets!</p>
<p><img loading="lazy" alt="Side by side picture of the same apple tree showing 3d mesh vs. gaussian splat photogrammetry techniques" src="https://3dstreet.org/assets/images/3d-mesh-vs-splat-16d7a8d0df770ca631c2b903d3b62a3f.jpg" width="1000" height="405" class="img_ev3q"></p>
<p>This is still an R&amp;D project, not yet a supported built-in feature of 3DStreet. In this post we share research and progress on how we are improving the visual appearance of compositing new scenes from multiple splats using depth buffer and selective splat discarding in three.js and A-Frame, underlying 3D frameworks supporting 3DStreet.</p>
<h1>A splatting explosion!</h1>
<p>A slew of gaussian splat tools have come to market -- creation apps for 3D scanning with your phone (<a href="https://poly.cam/" target="_blank" rel="noopener noreferrer">Polycam</a> and <a href="https://lumalabs.ai/" target="_blank" rel="noopener noreferrer">Luma</a>) and viewers for every platform and device imaginable (<a href="https://github.com/tomiwaAdey/awesome-gaussian-splatting?tab=readme-ov-file#rendering-and-visualisation-tools" target="_blank" rel="noopener noreferrer">too many to list</a>) and even <a href="https://playcanvas.com/super-splat" target="_blank" rel="noopener noreferrer">browser-based cropping and editing tools</a>.</p>
<p>However, much of the existing gaussian splat research and development focuses on scenes with just one single large splat.</p>
<p>With 3DStreet we're exploring something new -- constructing brand new street scenes from bits and pieces of existing 3D splats.</p>
<h1>The problem: multiple splats in three.js are Hard</h1>
<p>If we can draw one gaussian splat in our scene, why not more? Well it turns out it's Hard. Compositing wasn’t supported yet by the existing three.js / A-Frame splat viewing libraries so it resulted in things just not good enough for people to use as a product, like this fire hydrant and tree being occluded by a flower box further away.</p>
<p><img loading="lazy" alt="Picture of error in splat ordering resulting in distant objects incorrectly occluding closer objects" src="https://3dstreet.org/assets/images/splat-render-order-error-b7464f2e90d5d0dc4f2679db3e4052e6.jpg" width="592" height="338" class="img_ev3q"></p>
<p>To solve this problem, we collaborated with <a href="https://arthurmoug.in/" target="_blank" rel="noopener noreferrer">Arthur Mougin, a WebXR and full stack developer</a> who was excited to tackle a new challenge. Here is his writeup on how we enabled proper splat sorting, concluded by some discussion on what is coming next.</p>
<h1>Use depth buffer with <code>depthWrite:true</code></h1>
<p>After analyzing the shader and rendering pipeline of threejs, we identified first that we needed to have proper scene-level occlusion.</p>
<p>At the scene level, Splats are just classic opaque objects with a unique drawing method. That’s great because we can take advantage of the depth buffer. It’s a grayscale image that shaders use to know if their pixel below or above something that was already painted. By default, splats did not write into it, causing strange artifacts when the draw order does not match the depth order. Same thing for recursive occlusion.</p>
<p>So, we <a href="https://github.com/3DStreet/aframe-gaussian-splatting/pull/1/commits/dfa56ea471749e4864bfdedfcdd9c7c4aac9a656" target="_blank" rel="noopener noreferrer">added the ability to write the rendered splats to the depth buffer</a> with <code>depthWrite:true</code>. Turning it on improved our occlusion issues drastically.</p>
<p><img loading="lazy" alt="partial-splat-compositing-progress-occlusion-with-artifacts" src="https://3dstreet.org/assets/images/partial-splat-compositing-progress-occlusion-with-artifacts-4553061baecc737b7e9029329be883ef.jpg" width="863" height="525" class="img_ev3q"></p>
<h1>Fixing border and edge blending issues</h1>
<p>Sometimes the border is not completely clean, we also wanted a way to improve it.</p>
<p>It was done this time in the fragment shader, where discarding cause the pixel not to be drawn. <a href="https://github.com/3DStreet/aframe-gaussian-splatting/pull/1/commits/00d11e42f41a2adea824008ad81283001192176a" target="_blank" rel="noopener noreferrer">We compare there for each blob’s pixel their opacity, and if it’s lower than our limit, it’s not rendered.</a></p>
<p>This limit, the discard filter, has no effect when set to 0, but help cleanup unnecessary blobs that could ruin a proper transition between two splats. As it applies to all splat’s blobs, turning it on will impact the splats quality.</p>
<p><img loading="lazy" alt="gaussian-splat-depth-write-true-false-comparison" src="https://3dstreet.org/assets/images/gaussian-splat-depth-write-true-false-comparison-fa2440f90d576f4eba2e36feee1b5f98.jpg" width="1640" height="516" class="img_ev3q"></p>
<p>Unfortunately there is a trade off between different methods. As you can see in this next example below. On the right is the test scene with the original A-Frame splatting component that does not respect occlusion. On the left uses depthWrite which properly sorts the occlusion of the tree, fire hydrant, and flower box, but also results in artifacts especially visible on the bottom of the flower box where it meets the sidewalk.</p>
<p><img loading="lazy" alt="splat-compare-discard-filter-0-and-0.2" src="https://3dstreet.org/assets/images/splat-compare-discard-filter-0-and-0.2-f7b44cee1f4a98019c440e3dcf0acf88.jpg" width="1408" height="800" class="img_ev3q"></p>
<p>Adjusting <code>discardFilter</code> gives you control to find the right value, however as you continue to increase the <code>discardFilter</code> value approaching 1 the splats start to develop holes in the substrate and appear to be further apart.</p>
<p><img loading="lazy" alt="splat-compare-discard-filter-0.1-and-0.3" src="https://3dstreet.org/assets/images/splat-compare-discard-filter-0.1-and-0.3-62e5d345a053a2838d2752379ad95fcb.jpg" width="1408" height="800" class="img_ev3q"></p>
<p>A partially effective mitigation for the artifacts is to tightly crop your splats using a tool like <a href="https://playcanvas.com/super-splat" target="_blank" rel="noopener noreferrer">SuperSplat from PlayCanvas</a>.</p>
<h1>Updating the <code>aframe-gaussian-splatting</code> repository</h1>
<p>In the past we have been contributing changes directly to the <a href="https://github.com/quadjr/aframe-gaussian-splatting" target="_blank" rel="noopener noreferrer">original A-Frame Gaussian Splat library by quadjr</a>, and <a href="https://github.com/quadjr/aframe-gaussian-splatting/pull/25" target="_blank" rel="noopener noreferrer">Arthur has suggested a PR with these changes</a>, but we wanted to publish this piece before those are able to merged so we have forked this repo in the 3DStreet GitHub organization for now.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="github-httpsgithubcom3dstreetaframe-gaussian-splatting">GitHub: <a href="https://github.com/3dstreet/aframe-gaussian-splatting" target="_blank" rel="noopener noreferrer">https://github.com/3dstreet/aframe-gaussian-splatting</a><a href="https://3dstreet.org/blog/2023/12/21/gaussian-splat-compositing-for-constructed-street-scenes#github-httpsgithubcom3dstreetaframe-gaussian-splatting" class="hash-link" aria-label="Direct link to github-httpsgithubcom3dstreetaframe-gaussian-splatting" title="Direct link to github-httpsgithubcom3dstreetaframe-gaussian-splatting">​</a></h4>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="demo-scene-move-around-with-wasd-keys-https3dstreetgithubiosplat-playgroundbasiccompositing-demohtml">Demo scene (move around with <code>WASD</code> keys): <a href="https://3dstreet.github.io/splat-playground/basic/compositing-demo.html" target="_blank" rel="noopener noreferrer">https://3dstreet.github.io/splat-playground/basic/compositing-demo.html</a><a href="https://3dstreet.org/blog/2023/12/21/gaussian-splat-compositing-for-constructed-street-scenes#demo-scene-move-around-with-wasd-keys-https3dstreetgithubiosplat-playgroundbasiccompositing-demohtml" class="hash-link" aria-label="Direct link to demo-scene-move-around-with-wasd-keys-https3dstreetgithubiosplat-playgroundbasiccompositing-demohtml" title="Direct link to demo-scene-move-around-with-wasd-keys-https3dstreetgithubiosplat-playgroundbasiccompositing-demohtml">​</a></h4>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="demo-scene-source-also-uses-cutout-entity-httpsgithubcom3dstreetsplat-playgroundblobmainbasiccompositing-demohtml">Demo scene source (also uses cutout entity): <a href="https://github.com/3DStreet/splat-playground/blob/main/basic/compositing-demo.html" target="_blank" rel="noopener noreferrer">https://github.com/3DStreet/splat-playground/blob/main/basic/compositing-demo.html</a><a href="https://3dstreet.org/blog/2023/12/21/gaussian-splat-compositing-for-constructed-street-scenes#demo-scene-source-also-uses-cutout-entity-httpsgithubcom3dstreetsplat-playgroundblobmainbasiccompositing-demohtml" class="hash-link" aria-label="Direct link to demo-scene-source-also-uses-cutout-entity-httpsgithubcom3dstreetsplat-playgroundblobmainbasiccompositing-demohtml" title="Direct link to demo-scene-source-also-uses-cutout-entity-httpsgithubcom3dstreetsplat-playgroundblobmainbasiccompositing-demohtml">​</a></h4>
<h1>Combining rasterization methods to add splats to 3DStreet scenes</h1>
<p>Now that we have support in the library for splat compositing, it's time to test what these look like in 3DStreet scenes.</p>
<p>We created a sample scene that loads a 3DStreet street scene with manually placed splat entities placed around the scene in appropriate locations. This was a first attempt to see how well the splats might fit in to a scene and what changes we need to make to 3DStreet Editor to support managing these with a user interface.</p>
<p>This picture shows a side-by-side view of the splat and low-poly mesh counterparts for the hybrid sedan and bus stop.
<img loading="lazy" alt="3dstreet-splat-compositing-demo" src="https://3dstreet.org/assets/images/3dstreet-splat-compositing-demo-956f0b9516a47b5f42ebd24dd61de4fd.jpg" width="960" height="517" class="img_ev3q"></p>
<p>Since each of these splats are A-Frame entities, the 3DStreet Editor can provide a quick way to move them around and arrange a custom scene.
<img loading="lazy" alt="3dstreet-editor-changing-scene-compositing-gaussian-splat" src="https://3dstreet.org/assets/images/3dstreet-editor-changing-scene-compositing-gaussian-splat-9752b16f3f11e2079f946de51ceb9ad6.jpg" width="1194" height="828" class="img_ev3q"></p>
<h1>Try it for yourself</h1>
<p>We've created a proof of concept demo showing splats that I have scanned around San Francisco, combined with polygon mesh models automatically created from 3DStreet.</p>
<p><strong>Example scene (move around with <code>WASD</code> keys): <a href="https://github.com/3DStreet/splat-playground/" target="_blank" rel="noopener noreferrer">https://github.com/3DStreet/splat-playground/</a></strong></p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_BuS1"><p>Gaussian Splats in 3DStreet is a research project. Sometimes you need to reload once or twice for the splats to look better. If you're really adventurous press ctl + alt + i to access Editor but saving these scenes won't work and it will probably break. Be careful using this for real projects.</p></div></div>
<p>Does it work in WebXR? Yes, barely -- it requires a powerful device to maintain frame rate. Quest headsets and older phones have a hard time rendering this at full framerate.</p>
<h1>What's next</h1>
<p>This is still a research technology. Even just in the past week there was a <a href="https://lumalabs.ai/luma-web-library" target="_blank" rel="noopener noreferrer">whole new WegGL splat viewing library released by Luma AI</a> and more research on this topic seems to drop every week. Likely the method that we've come up with will be replaced with a fancy new algorithm soon.</p>
<p>We'll keep iterating on the applications of this technology for street safety and more general urban design use cases. If this resonates with users we can explore how to make this accessible so that all users can create custom splat scenes with models they scan from their own streets.</p>
<p><a href="https://discord.gg/VN242sx9qu" target="_blank" rel="noopener noreferrer">Join our community to continue the conversation!</a></p>
<h1>Video version of this post</h1>
<iframe width="580" height="420" src="https://www.youtube.com/embed/Fy8PefDy5VY?si=pJ7F6j_mmmA2yo31" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"></iframe>]]></content>
        <author>
            <name>Kieran Farr</name>
            <uri>https://github.com/kfarr</uri>
        </author>
        <author>
            <name>Arthur Mougin</name>
            <uri>https://github.com/arthurmougin</uri>
        </author>
        <category label="gaussian splats" term="gaussian splats"/>
        <category label="splats" term="splats"/>
        <category label="photogrammetry" term="photogrammetry"/>
    </entry>
</feed>